{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from datetime import datetime\n",
    "from urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'data' not in os.listdir():\n",
    "    os.mkdir('data') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 현재 진행중인 이벤트 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://maplestory.nexon.com/News/Event/Ongoing'\n",
    "browser.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=[]\n",
    "i=0\n",
    "while True:\n",
    "    event_button_list = browser.find_elements('css selector', 'div.event_board > ul >li')\n",
    "    html = browser.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    image_list = soup.select('dt>a>img')\n",
    "    for j, image in enumerate(image_list):\n",
    "        urlretrieve(image['src'],f'image/event_{j}.jpg')\n",
    "    event_button_list[i].click()\n",
    "\n",
    "    j=0\n",
    "    html = browser.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    title = soup.select('p.qs_title>span')[0].text\n",
    "    duration = soup.select('div.qs_info_wrap > span.event_date')[0].text\n",
    "    click_num = soup.select('div.qs_info>p')[0].text\n",
    "    reply_num = soup.select('div.reply_title>h2>span')[0].text\n",
    "    \n",
    "    while True:\n",
    "        reply_button_list = browser.find_elements('css selector','div.page_numb2>a')\n",
    "        reply_button_list[j].click()\n",
    "        time.sleep(1)\n",
    "        html = browser.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        reply = soup.select('div.reply>p.reply_text')\n",
    "        for r in reply:\n",
    "            data= [title, duration, click_num, reply_num, r.text]\n",
    "            result.append(data)\n",
    "        j+=1\n",
    "        if j==len(reply_button_list):\n",
    "            break\n",
    "    browser.get(url)\n",
    "    i+=1\n",
    "    if i==len(event_button_list):\n",
    "        break\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(result)\n",
    "df.columns = ['title', 'duration', 'click_num', 'reply_num', 'reply']\n",
    "df.to_csv(\"data/ongoing_event.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 썬데이 메이플 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.fmkorea.com/index.php?mid=maple&category=1135601723'\n",
    "browser.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = browser.find_elements('css selector', 'input#bd_srch_btm_itx_1135415169')[0]\n",
    "drop_down = browser.find_element('css selector','span.btn_img select')\n",
    "search = \"썬데이 메이플(2023)\"\n",
    "\n",
    "input_text.send_keys(search)\n",
    "select = Select(drop_down)\n",
    "select.select_by_value('title')\n",
    "input_text.send_keys(Keys.RETURN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=[]\n",
    "while True:\n",
    "    i=0\n",
    "    html = browser.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    now = soup.select('strong.direction')[0].text.strip()\n",
    "\n",
    "    while True:\n",
    "        title_list= browser.find_elements('css selector','td.title.hotdeal_var8 > a' )\n",
    "        time.sleep(1)\n",
    "        title_list = title_list[::2]\n",
    "        title_list[i].click()\n",
    "        time.sleep(1)\n",
    "        html = browser.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        now = soup.select('strong.direction')[0].text.strip()\n",
    "        title = soup.select('span.np_18px_span')[0].text\n",
    "        info = soup.select('span>b')\n",
    "        view =info[0].text\n",
    "        recom_num = info[1].text\n",
    "        reply_num = info[2].text\n",
    "        reply_list = soup.select('div.comment-content')\n",
    "        time.sleep(1)\n",
    "        for reply in reply_list:\n",
    "            r = reply.text\n",
    "            data = [title, view, recom_num, reply_num, r]\n",
    "            result.append(data)\n",
    "        i+=1\n",
    "        time.sleep(1)\n",
    "        if i==len(title_list):\n",
    "            break\n",
    "    if now=='다음':\n",
    "        break\n",
    "    else:\n",
    "        button = browser.find_elements('css selector','a.direction')[0]\n",
    "        button.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_date_format(title):\n",
    "    date_str = title.split(' ')[0]\n",
    "    try:\n",
    "        date_obj = datetime.strptime(date_str, '%Y.%m.%d')\n",
    "        new_date_str = f\"{date_obj.year}년 {date_obj.month}월 {date_obj.day}일\"\n",
    "        return title.replace(date_str, new_date_str)\n",
    "    except ValueError:\n",
    "        return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(result)\n",
    "df.columns = ['title', 'view', 'recommendation number', 'reply number', 'reply']\n",
    "df['title'] = df['title'].apply(convert_date_format)\n",
    "df[['year', 'month', 'day']] = df['title'].str.extract(r'(\\d{4})년 (\\d{1,2})월 (\\d{1,2})일')\n",
    "df['datetime'] = pd.to_datetime(df[['year', 'month', 'day']])\n",
    "df.to_csv(\"data/sunday_maple_event.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 메이플 직업 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "maple_jobs_dict ={'히어로':'혀로',\n",
    "                  '팔라딘':'팔라',\n",
    "                  '다크나이트':'닼나',\n",
    "                  '소울마스터':'소마',\n",
    "                  '미하일':'미하일',\n",
    "                  '블래스터':'블래',\n",
    "                  '데몬슬레이어':'데슬',\n",
    "                  '데몬어벤져':'데벤',\n",
    "                  '아란':'아란',\n",
    "                  '카이저':'카이저',\n",
    "                  '아델':'아델',\n",
    "                  '제로':'제로',\n",
    "                  '아크메이지(불,독)':'불독',\n",
    "                  '아크메이지(썬,콜)':'선콜',\n",
    "                  '비숍':'숍',\n",
    "                  '플레임위자드':'플위',\n",
    "                  '배틀메이지':'배메',\n",
    "                  '에반':'에반',\n",
    "                '루미너스':'루미',\n",
    "                '일리움':'일리움',\n",
    "                '라라':'라라',\n",
    "                '키네시스':'키네',\n",
    "                '보우마스터':'보마',\n",
    "                '신궁':'신궁',\n",
    "                '패스파인더':'패파',\n",
    "                '윈드브레이커':'윈브',\n",
    "                '와일드헌터':'와헌',\n",
    "                '메르세데스':'메세',\n",
    "                '카인':'카인',\n",
    "                '나이트로드':'나로',\n",
    "                '섀도어':'섀도어',\n",
    "                '듀얼블레이드':'듀블',\n",
    "                '나이트워커':'나워',\n",
    "                '제논':'제논',\n",
    "                '팬텀':'팬텀',\n",
    "                '카데나':'카데나',\n",
    "                '칼리':'칼리',\n",
    "                '호영':'호영',\n",
    "                '바이퍼':'바이퍼',\n",
    "                '캡틴':'캡틴',\n",
    "                '캐논슈터':'캐슈',\n",
    "                '스트라이커':'스커',\n",
    "                '메카닉':'메카닉',\n",
    "                '제논':'제논',\n",
    "                '은월':'은월',\n",
    "                '엔젤릭버스터':'엔버',\n",
    "                '아크':'아크'\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.fmkorea.com/maple'\n",
    "browser.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=[]\n",
    "drop_down = browser.find_element('css selector','span.btn_img select')\n",
    "select = Select(drop_down)\n",
    "select.select_by_value('title')\n",
    "for key, value in maple_jobs_dict.items():\n",
    "    if key==value:\n",
    "        input_text = browser.find_elements('css selector', 'input#bd_srch_btm_itx_1135415169')[0]\n",
    "        time.sleep(1)\n",
    "        input_text.send_keys(key)\n",
    "        input_text.send_keys(Keys.RETURN)\n",
    "        time.sleep(1)\n",
    "        url=browser.current_url\n",
    "        for j in range(1, 10):\n",
    "            new_url = url+f'&page={j}'\n",
    "            browser.get(new_url)\n",
    "            time.sleep(1)\n",
    "            html = browser.page_source\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            time.sleep(1)\n",
    "            cate_list = soup.select('td.cate')\n",
    "            title_reply_list = soup.select('td.title.hotdeal_var8')\n",
    "            date_list = soup.select('td.time')\n",
    "            view_list = soup.select('td.m_no')[::2]\n",
    "            recommend_list = soup.select('td.m_no')[1::2]\n",
    "            for k in range(len(cate_list)):\n",
    "                cate = cate_list[k].text.strip()\n",
    "                title = title_reply_list[k].select('a.hx')[0].text.strip()\n",
    "                if len(title_reply_list[k].select('a.replyNum'))==0:\n",
    "                    reply = '0'\n",
    "                else:\n",
    "                    reply = title_reply_list[k].select('a.replyNum')[0].text.strip()\n",
    "                date = date_list[k].text.strip()\n",
    "                view = view_list[k].text.strip()\n",
    "                if recommend_list[k].text.strip()=='':\n",
    "                    recommend = '0'\n",
    "                else:\n",
    "                    recommend = recommend_list[k].text.strip()\n",
    "                data = [key, cate, title, reply, date, view, recommend]\n",
    "                result.append(data)\n",
    "            if len(soup.select('p.no_doc'))!=0 and soup.select('p.no_doc')[0].text.strip()=='등록된 글이 없습니다.':\n",
    "                break\n",
    "        input_text = browser.find_elements('css selector', 'input#bd_srch_btm_itx_1135415169')[0]\n",
    "        time.sleep(1)\n",
    "        input_text.clear()\n",
    "    else:\n",
    "        for i in [key, value]:\n",
    "            input_text = browser.find_elements('css selector', 'input#bd_srch_btm_itx_1135415169')[0]\n",
    "            time.sleep(1)\n",
    "            input_text.send_keys(i)\n",
    "            input_text.send_keys(Keys.RETURN)\n",
    "            time.sleep(1)\n",
    "            url=browser.current_url\n",
    "            for j in range(1, 10):\n",
    "                new_url = url+f'&page={j}'\n",
    "                browser.get(new_url)\n",
    "                time.sleep(1)\n",
    "                html = browser.page_source\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "                time.sleep(1)\n",
    "                cate_list = soup.select('td.cate')\n",
    "                title_reply_list = soup.select('td.title.hotdeal_var8')\n",
    "                date_list = soup.select('td.time')\n",
    "                view_list = soup.select('td.m_no')[::2]\n",
    "                recommend_list = soup.select('td.m_no')[1::2]\n",
    "                for k in range(len(cate_list)):\n",
    "                    cate = cate_list[k].text.strip()\n",
    "                    title = title_reply_list[k].select('a.hx')[0].text.strip()\n",
    "                    if len(title_reply_list[k].select('a.replyNum'))==0:\n",
    "                        reply = '0'\n",
    "                    else:\n",
    "                        reply = title_reply_list[k].select('a.replyNum')[0].text.strip()\n",
    "                    date = date_list[k].text.strip()\n",
    "                    view = view_list[k].text.strip()\n",
    "                    if recommend_list[k].text.strip()=='':\n",
    "                        recommend = '0'\n",
    "                    else:\n",
    "                        recommend = recommend_list[k].text.strip()\n",
    "                    data = [key, cate, title, reply, date, view, recommend]\n",
    "                    result.append(data)\n",
    "                if len(soup.select('p.no_doc'))!=0 and soup.select('p.no_doc')[0].text.strip()=='등록된 글이 없습니다.':\n",
    "                    break\n",
    "            input_text = browser.find_elements('css selector', 'input#bd_srch_btm_itx_1135415169')[0]\n",
    "            time.sleep(1)\n",
    "            input_text.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(result)\n",
    "df.columns = ['job', 'category', 'title', 'reply', 'date', 'view','recommend']\n",
    "df = df.drop_duplicates()\n",
    "today = datetime.today().strftime('%Y.%m.%d')\n",
    "df.loc[df['date'].str.contains(':'), 'date'] = today\n",
    "df.to_csv(\"data/jobs.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
